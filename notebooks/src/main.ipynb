{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running through shell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/amarmesic/Documents/tudelft/MLG/cyclone-tracking\n",
      "LICENSE          __init__.py      \u001b[34mexperiments\u001b[m\u001b[m      requirements.txt\n",
      "README.md        \u001b[34mdata\u001b[m\u001b[m             \u001b[34mnotebooks\u001b[m\u001b[m        \u001b[34msrc\u001b[m\u001b[m\n",
      "GAT\n",
      "Train loss after epoch 1: 0.5022062435109391\n",
      "Test loss after epoch 1: 0.5481403823626243\n",
      "Train loss after epoch 2: 0.4977902245317769\n",
      "Test loss after epoch 2: 0.5435808381791842\n",
      "Train loss after epoch 3: 0.4928109984622042\n",
      "Test loss after epoch 3: 0.53702328568798\n",
      "Train loss after epoch 4: 0.4856480041630248\n",
      "Test loss after epoch 4: 0.5278385513919895\n",
      "Train loss after epoch 5: 0.47605272592642367\n",
      "Test loss after epoch 5: 0.5160110643354513\n",
      "Train loss after epoch 6: 0.4639834399916168\n",
      "Test loss after epoch 6: 0.501630635584815\n",
      "Train loss after epoch 7: 0.4495621468776312\n",
      "Test loss after epoch 7: 0.48466660309646087\n",
      "Train loss after epoch 8: 0.432861989379948\n",
      "Test loss after epoch 8: 0.4657545716075574\n",
      "Train loss after epoch 9: 0.41516188856882924\n",
      "Test loss after epoch 9: 0.44643136404328426\n",
      "Train loss after epoch 10: 0.39783123950672966\n",
      "Test loss after epoch 10: 0.42963294760655546\n",
      "Train loss after epoch 11: 0.38397673078072375\n",
      "Test loss after epoch 11: 0.4168786840923762\n",
      "Train loss after epoch 12: 0.373817756644681\n",
      "Test loss after epoch 12: 0.4080022916955463\n",
      "Train loss after epoch 13: 0.3664711115197239\n",
      "Test loss after epoch 13: 0.4007120445623236\n",
      "Train loss after epoch 14: 0.3600405915680095\n",
      "Test loss after epoch 14: 0.3939905186830941\n",
      "Train loss after epoch 15: 0.3539954490131802\n",
      "Test loss after epoch 15: 0.3877820261454178\n",
      "Train loss after epoch 16: 0.34855548922832197\n",
      "Test loss after epoch 16: 0.3823680322049028\n",
      "Train loss after epoch 17: 0.3439470315590883\n",
      "Test loss after epoch 17: 0.3779419296878879\n",
      "Train loss after epoch 18: 0.34023083810113436\n",
      "Test loss after epoch 18: 0.37452610165385875\n",
      "Train loss after epoch 19: 0.3373667773527977\n",
      "Test loss after epoch 19: 0.3719124864723723\n",
      "Train loss after epoch 20: 0.3350937152520204\n",
      "Test loss after epoch 20: 0.36978416220616483\n",
      "Train loss after epoch 21: 0.3331896216950865\n",
      "Test loss after epoch 21: 0.36814449904328683\n",
      "Train loss after epoch 22: 0.3317845919702807\n",
      "Test loss after epoch 22: 0.36675253864062035\n",
      "Train loss after epoch 23: 0.3301917984444871\n",
      "Test loss after epoch 23: 0.3657268255443896\n",
      "Train loss after epoch 24: 0.32908859415950936\n",
      "Test loss after epoch 24: 0.36531315112518054\n",
      "Train loss after epoch 25: 0.32831910252571106\n",
      "Test loss after epoch 25: 0.36597447173070097\n",
      "Train loss after epoch 26: 0.32775210697426754\n",
      "Test loss after epoch 26: 0.3670781588150283\n",
      "Train loss after epoch 27: 0.32765072558680153\n",
      "Test loss after epoch 27: 0.3677443579091864\n",
      "Train loss after epoch 28: 0.3269051354155581\n",
      "Test loss after epoch 28: 0.3633616576760502\n",
      "Train loss after epoch 29: 0.3246871367988423\n",
      "Test loss after epoch 29: 0.3592726972143529\n",
      "Train loss after epoch 30: 0.32211256969688284\n",
      "Test loss after epoch 30: 0.355422686722319\n",
      "/Users/amarmesic/Documents/tudelft/MLG/cyclone-tracking/notebooks/src\n",
      "main.ipynb\n"
     ]
    }
   ],
   "source": [
    "%cd ../..\n",
    "!ls\n",
    "\n",
    "!python -m src.main experiments/baseline\n",
    "\n",
    "%cd notebooks/src\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running in nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Directory: c:\\Users\\aratr\\cyclone-tracking\\notebooks\\src\n",
      "c:\\Users\\aratr\\cyclone-tracking\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "print(\"Current Directory:\", current_dir)\n",
    "\n",
    "# Check if the current directory ends with 'notebooks/src'\n",
    "if current_dir.endswith('notebooks\\\\src'):\n",
    "    %cd ../..\n",
    "else:\n",
    "    print(\"Current directory does not end with 'notebooks/src'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from src.main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train from dataset shape:  torch.Size([780, 64, 32, 2, 12])\n",
      "y_train from dataset shape:  torch.Size([780, 64, 32, 1, 12])\n",
      "Train loss after epoch 1: 0.8574490513557043\n",
      "Test loss after epoch 1: 0.6917916653411729\n",
      "Train loss after epoch 2: 0.5366488946553988\n",
      "Test loss after epoch 2: 0.44635952112017846\n",
      "Train loss after epoch 3: 0.3694806522474839\n",
      "Test loss after epoch 3: 0.32266124596401136\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 11\u001b[0m\n\u001b[0;32m      7\u001b[0m results_save_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(experiment_directory, FolderNames\u001b[38;5;241m.\u001b[39mRESULTS)\n\u001b[0;32m      9\u001b[0m experiment_config \u001b[38;5;241m=\u001b[39m ExperimentConfig(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mload_from_json_file(experiment_config_path))\n\u001b[1;32m---> 11\u001b[0m \u001b[43mrun_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexperiment_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_save_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresults_save_dir\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aratr\\cyclone-tracking\\src\\main.py:75\u001b[0m, in \u001b[0;36mrun_experiment\u001b[1;34m(experiment_config, results_save_dir)\u001b[0m\n\u001b[0;32m     71\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     73\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m Adam(params\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39mexperiment_config\u001b[38;5;241m.\u001b[39mlearning_rate)\n\u001b[1;32m---> 75\u001b[0m train_losses, test_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_datalaoder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexperiment_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprint_losses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     84\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwandb_log\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m     85\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     87\u001b[0m results \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     88\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_losses,\n\u001b[0;32m     89\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_losses\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_losses,\n\u001b[0;32m     90\u001b[0m }\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[1;32mc:\\Users\\aratr\\cyclone-tracking\\src\\train.py:76\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_datalaoder, test_dataloader, optimiser, num_epochs, device, config, print_losses, wandb_log)\u001b[0m\n\u001b[0;32m     70\u001b[0m     wandb\u001b[38;5;241m.\u001b[39minit(\n\u001b[0;32m     71\u001b[0m         entity\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgraphml-group4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     72\u001b[0m         project\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweather-prediction\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     73\u001b[0m         config\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(config))\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 76\u001b[0m     epoch_train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     78\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimiser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimiser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     79\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_datalaoder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     81\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m print_losses:\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain loss after epoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch_train_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aratr\\cyclone-tracking\\src\\train.py:25\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[1;34m(model, train_dataloader, optimiser, loss_fn, device)\u001b[0m\n\u001b[0;32m     23\u001b[0m outs \u001b[38;5;241m=\u001b[39m model(X\u001b[38;5;241m=\u001b[39mX)\n\u001b[0;32m     24\u001b[0m batch_loss \u001b[38;5;241m=\u001b[39m loss_fn(outs, y)\n\u001b[1;32m---> 25\u001b[0m \u001b[43mbatch_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m optimiser\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     27\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_loss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\aratr\\anaconda3\\envs\\MLGD\\Lib\\site-packages\\torch\\_tensor.py:525\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    517\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    518\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    523\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[1;32m--> 525\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aratr\\anaconda3\\envs\\MLGD\\Lib\\site-packages\\torch\\autograd\\__init__.py:267\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    262\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 267\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aratr\\anaconda3\\envs\\MLGD\\Lib\\site-packages\\torch\\autograd\\graph.py:744\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    745\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[0;32m    746\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[0;32m    747\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    748\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "experiment_directory = 'experiments\\\\baseline2'\n",
    "\n",
    "experiment_config_path = os.path.join(\n",
    "    experiment_directory, FileNames.EXPERIMENT_CONFIG\n",
    ")\n",
    "\n",
    "results_save_dir = os.path.join(experiment_directory, FolderNames.RESULTS)\n",
    "\n",
    "experiment_config = ExperimentConfig(**load_from_json_file(experiment_config_path))\n",
    "\n",
    "run_experiment(\n",
    "    experiment_config=experiment_config, results_save_dir=results_save_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
